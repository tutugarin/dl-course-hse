{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gtpdmtxfxcp6ao6bbv105a",
    "execution_id": "b5f119c6-e463-4366-8d26-be5a247f8750"
   },
   "source": [
    "# FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "cellId": "6jxqyxq2ggd99z89yyep1i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.ops as ops\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "cellId": "q4snbjp2nnqpufoypiq3i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtutugarin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "cellId": "xay9yuadxiaywagv49d9fg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "cfm66bunw8i69h9danhfa9",
    "execution_id": "8515fe8f-35cf-4ce8-9678-b21648dbc76d"
   },
   "source": [
    "## Напишем класс для работы с фотографиями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cellId": "0zwus44m5c0sxzccieecffq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root: str, transform: transforms.Compose = None,\n",
    "            image_dirname: str = 'trainval/trainval', labels=None) -> None:\n",
    "        super().__init__()\n",
    "        self._root: str = root\n",
    "        self._image_dirname: str = image_dirname\n",
    "\n",
    "        self._transform: transforms.Compose = transform\n",
    "        if self._transform is None:\n",
    "            self._transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self._labels = labels\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        label, filename = self._labels.iloc[item]['Label'], self._labels.iloc[item]['Id']\n",
    "        image = Image.open(os.path.join(self._root, self._image_dirname, filename)).convert('RGB')\n",
    "        image = self._transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ledbp3oa4nm63rtpzpz83q",
    "execution_id": "4315737b-b4ff-4ff0-9bec-e1e1616779cc"
   },
   "source": [
    "## Посчитаем статистики на фотографиях:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "cellId": "o0xeqo0fvajzjiku12zy69"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "N_CHANNELS = 3\n",
    "\n",
    "root = '/home/jupyter/mnt/datasets/bhw1'\n",
    "train_image_dirname = 'trainval/trainval'\n",
    "test_image_dirname = 'test/test'\n",
    "labels_filename = 'labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8k3akr084cslfo5wwpiyj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "labels = pd.read_csv(f'{root}/{labels_filename}')\n",
    "full_dataset = ImageDataset(root, image_dirname=train_image_dirname, labels=labels)\n",
    "full_dataloader = torch.utils.data.DataLoader(full_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "mean = torch.zeros(N_CHANNELS)\n",
    "std = torch.zeros(N_CHANNELS)\n",
    "for images, _ in tqdm(full_dataloader):\n",
    "    for i in range(N_CHANNELS):\n",
    "        mean[i] += images[:,i,:,:].mean()\n",
    "        std[i] += images[:,i,:,:].std()\n",
    "\n",
    "mean.div_(len(full_dataloader))\n",
    "std.div_(len(full_dataloader))\n",
    "print(f'{mean=}, {std=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oc1zja32fdlkzsuisycue",
    "execution_id": "a4026d01-5113-407f-92ff-921dad2cddfb"
   },
   "source": [
    "## Напишем функцию, которая будет делить наш датасет и возвращать два даталоадера: для трейна и для вала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "cellId": "havz8bzzqg8jk1vq641l9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def get_loaders(root: str, train_transform: transforms.Compose = None,\n",
    "        test_size: float = 0.3, batch_size: int = 64,\n",
    "        image_dirname: str = 'trainval/trainval', labels_filename: str = 'labels.csv'):\n",
    "    \n",
    "    test_transformer = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5696, 0.5450, 0.4936], [0.2430, 0.2375, 0.2555]),\n",
    "    ])\n",
    "    \n",
    "    labels = pd.read_csv(f'{root}/{labels_filename}')\n",
    "    train_idx, valid_idx = torch.utils.data.random_split(\n",
    "        np.arange(len(labels)), \n",
    "        [1 - test_size, test_size], \n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    trainset = ImageDataset(root, train_transform, image_dirname, labels.iloc[train_idx.indices])\n",
    "    valset = ImageDataset(root, test_transformer, image_dirname, labels.iloc[valid_idx.indices])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "k6sg1gjy3ridsixy55hfk8",
    "execution_id": "a71557fd-5ee9-4c95-88e7-559501b1b5ab"
   },
   "source": [
    "## Объявим наши аугментации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "cellId": "bgfyni50448bzicjvfwuj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=5),\n",
    "    ], p=0.3),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5696, 0.5450, 0.4936], [0.2430, 0.2375, 0.2555]),\n",
    "    \n",
    "    transforms.RandomErasing(),\n",
    "])\n",
    "\n",
    "train_loader, val_loader = get_loaders(root='/home/jupyter/mnt/datasets/bhw1',  batch_size=32, train_transform=transform, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "cellId": "9uphr28y64wd4edg6rads"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "len(train_loader) / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "lp4sgn6fsqmgaw05juicu7",
    "execution_id": "a9ccd825-ca2c-4a9b-b4c6-0d97aaf55d65"
   },
   "source": [
    "## Напишем функции для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "cellId": "0vibiknl7kg9uny0bzm1wv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def test(model, loader, loss_func):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    model.eval()\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(data)\n",
    "            loss = loss_func(logits, target)\n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        acc = torch.sum((logits.argmax(dim=1) == target).to(torch.float32))\n",
    "        acc_log.append(acc.item()) \n",
    "        \n",
    "    return np.mean(loss_log), np.sum(acc_log) / len(loader.dataset)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, loss_func, scheduler):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    model.train()\n",
    "    \n",
    "    pbar = tqdm(train_loader)\n",
    "    for data, target in pbar:\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = loss_func(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if scheduler is not None:\n",
    "#             scheduler.step()\n",
    "        \n",
    "        loss_log.append(loss.item())\n",
    "        \n",
    "        acc = torch.sum((logits.argmax(dim=1) == target).to(torch.float32))\n",
    "        acc_log.append(acc.item())\n",
    "\n",
    "    return np.mean(loss_log), np.sum(acc_log) / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def train(model, optimizer, n_epochs, train_loader, val_loader, scheduler, loss_func):\n",
    "    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if epoch % 20 == 0:\n",
    "            torch.save(model.state_dict(), f'Resnet38_{epoch=}.pt')\n",
    "            torch.save(optimizer.state_dict(), f'opt_Resnet38_{epoch=}.pt')\n",
    "        train_loss, train_acc = train_epoch(model, optimizer, train_loader, loss_func, scheduler)\n",
    "        val_loss, val_acc = test(model, val_loader, loss_func)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_acc)\n",
    "        \n",
    "        train_loss_log.append(train_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "        \n",
    "        val_loss_log.append(val_loss)\n",
    "        val_acc_log.append(val_acc)\n",
    "        \n",
    "#         lasr_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        metrics = {\n",
    "            \"train loss\": train_loss, \n",
    "            \"val loss\": val_loss,\n",
    "            \"train acc\": train_acc, \n",
    "            \"val acc\": val_acc,\n",
    "#             \"lasr lr\": lasr_lr\n",
    "            \n",
    "        }\n",
    "\n",
    "        wandb.log(metrics)\n",
    "        \n",
    "        clear_output()\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\" train loss: {train_loss}, train acc: {train_acc}\")\n",
    "        print(f\" val loss: {val_loss}, val acc: {val_acc}\")\n",
    "#         if scheduler is not None:\n",
    "#             print(f\" last used lr: {lasr_lr}\\n\")\n",
    "\n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "j3nj8gzumqgi2ail7zg23r",
    "execution_id": "29526027-97a3-438a-9418-cf99181ea200"
   },
   "source": [
    "## Напишем функцию, которая будет сохранять предсказыванные лейблы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "cellId": "uzhxth6ohbhqppm9lttb5n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def get_test_labels(model):\n",
    "    model.eval()\n",
    "    test_labels = []\n",
    "    \n",
    "    test_transformer = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5696, 0.5450, 0.4936], [0.2430, 0.2375, 0.2555]),\n",
    "    ])\n",
    "\n",
    "    for filename in os.listdir('/home/jupyter/mnt/datasets/bhw1/test/test'):\n",
    "        image = Image.open(f'/home/jupyter/mnt/datasets/bhw1/test/test/{filename}').convert('RGB')\n",
    "        image = test_transformer(image).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = model(image)\n",
    "\n",
    "        test_labels.append({'Id': filename, 'Label': logits.argmax(dim=1).item()})\n",
    "        \n",
    "    with open('labels_test.csv', 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, ('Id', 'Label'))\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "bm0l2mpx8rd0sslpydmjn7o",
    "execution_id": "fe66f36b-e039-432d-ba41-53e1599e6fc9"
   },
   "source": [
    "## Возьмем непредобученный `ResNet50` из `torchvision.models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellId": "d8gl62bnf3het5lbagzay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/work/resources/image-classification200/wandb/run-20221206_070746-26ccnijz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tutugarin/image-classification/runs/26ccnijz\" target=\"_blank\">fearless-spaceship-165</a></strong> to <a href=\"https://wandb.ai/tutugarin/image-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/tutugarin/image-classification/runs/26ccnijz?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f465c2c4790>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "config = {\n",
    "    \"dataset\": \"bhw1-dataset\",\n",
    "    \"machine\": \"g2.mig\",\n",
    "    \"arch\": 'ResNet50',\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"optim\": \"SGD\",\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"image-classification\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cellId": "ejdfg2xw3mvs8cm0fgcvt",
    "execution_id": "80422867-e3a6-4221-9678-42877d485573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      " train loss: 0.012789208430622239, train acc: 0.996425\n",
      " val loss: 2.817658856487274, val acc: 0.615\n",
      " last used lr: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "model = models.resnet50(num_classes=200, weights=None).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,\n",
    ")\n",
    "\n",
    "tr_loss_log, tr_acc_log, val_loss_log, val_acc_log = train(model, optimizer, EPOCHS, train_loader, val_loader, scheduler, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cellId": "teol0m3wvbfvexvh8c2yse",
    "execution_id": "34fc6c7b-1fb6-4b6f-8a61-c12ccd2a3144"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "get_test_labels(model)\n",
    "torch.save(model.state_dict(), 'Resnet50-part1.pt')\n",
    "torch.save(optimizer.state_dict(), 'opt-Resnet50-part1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "eubibkpish4eb7p9hdhk7d",
    "execution_id": "7b763aeb-d996-44c4-83ba-6822bd560c40"
   },
   "source": [
    "## Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cellId": "2lx9w9tc0i3kwect84jhe"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "    \n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness=0.01),\n",
    "        transforms.ColorJitter(contrast=0.01),\n",
    "        transforms.ColorJitter(saturation=0.01),\n",
    "    ], p=0.1),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=5),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.RandomEqualize(),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5696, 0.5450, 0.4936], [0.2430, 0.2375, 0.2555]),\n",
    "    \n",
    "    transforms.RandomErasing(),\n",
    "])\n",
    "\n",
    "train_loader, val_loader = get_loaders(root='/home/jupyter/mnt/datasets/bhw1',  batch_size=32, train_transform=transform, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cellId": "vgf626sa2rp8ohmxet3dj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/work/resources/image-classification200/wandb/run-20221207_140853-3mwcw8rn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tutugarin/image-classification/runs/3mwcw8rn\" target=\"_blank\">golden-fire-168</a></strong> to <a href=\"https://wandb.ai/tutugarin/image-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/tutugarin/image-classification/runs/3mwcw8rn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbcf121e7f0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "config = {\n",
    "    \"dataset\": \"bhw1-dataset\",\n",
    "    \"machine\": \"g2.mig\",\n",
    "    \"arch\": 'resnet50',\n",
    "    \"weight_decay\": 3 * 1e-5,\n",
    "    \"optim\": \"SGD\",\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"image-classification\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cellId": "qd8w0pxh3amuxby4wp4u3",
    "execution_id": "53f6a6bb-ebd2-48cc-9ed6-c68df8ecfdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      " train loss: 0.35560950281918047, train acc: 0.9056\n",
      " val loss: 1.6498496806144713, val acc: 0.6624\n",
      " last used lr: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "model = models.resnet50(num_classes=200, weights=None).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=3 * 1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,\n",
    ")\n",
    "\n",
    "tr_loss_log, tr_acc_log, val_loss_log, val_acc_log = train(model, optimizer, EPOCHS, train_loader, val_loader, scheduler, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cellId": "u5xhb2qf8w8guype2icqx",
    "execution_id": "f7043099-986a-4fdf-a531-7529803abaf9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "get_test_labels(model)\n",
    "torch.save(model.state_dict(), 'Resnet50-part2.pt')\n",
    "torch.save(optimizer.state_dict(), 'opt-Resnet50-part2.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "c283c906-221b-4864-affd-82718c59b0c9",
  "notebookPath": "image-classification200/checkpoint.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "ydsNotebookPath": "modeltraining.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
